{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobspy import scrape_jobs\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your configs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_old = 72\n",
    "result_wanted =30\n",
    "job_title = '.net'\n",
    "Locations = {\n",
    "    \"Netherlands\": result_wanted,\n",
    "    \"Germany\": result_wanted,\n",
    "    \"Belgium\": result_wanted,\n",
    "    \"Austria\": result_wanted,\n",
    "    \"Australia\": result_wanted,\n",
    "    \"Canada\": result_wanted,\n",
    "    \"France\": result_wanted,\n",
    "    \"Ireland\": result_wanted,\n",
    "    \"Italy\": result_wanted,\n",
    "    \"Spain\": result_wanted,\n",
    "    \"UK\": result_wanted\n",
    "}\n",
    "job_sefixes = [\"relocation\", \"relocate\", \"visa sponsorship\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 15:01:26,628 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:01:26,629 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:01:27,220 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:01:27,505 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:01:27,507 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:01:28,550 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:01:30,012 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:01:30,438 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:01:34,152 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:01:45,458 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:01:45,509 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:01:45,510 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:01:45,842 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:01:46,154 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:01:46,155 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:01:46,337 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:01:47,171 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:01:47,721 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:01:52,395 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:01:53,020 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:01:53,050 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:01:53,050 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:01:53,552 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:01:53,913 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:01:53,914 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:01:54,185 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:01:55,046 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:01:55,496 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:01:59,527 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:02:00,101 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:02:00,178 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:02:00,178 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:02:00,445 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:02:00,446 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:02:01,954 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:02:02,354 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:02:04,285 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:02:09,172 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-09-22 15:02:13,032 - JobSpy - INFO - LinkedIn search page: 4\n",
      "2024-09-22 15:02:13,520 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:02:13,551 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:02:13,551 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:02:13,802 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:02:13,803 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:02:15,260 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:02:15,612 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:02:18,836 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:02:19,357 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:02:19,377 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:02:19,378 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:02:19,644 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:02:19,646 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:02:20,576 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:02:20,962 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:02:27,142 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:02:32,002 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-09-22 15:02:33,294 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:02:33,308 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:02:33,309 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:02:33,722 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:02:33,803 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:02:34,043 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:02:34,045 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:02:34,705 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:02:35,547 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:02:35,955 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:02:35,974 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:02:35,975 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:02:36,244 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:02:36,499 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:02:36,500 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:02:42,904 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:02:43,325 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:03:00,101 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:03:00,914 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:03:01,325 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:03:01,343 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:03:01,344 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:03:01,640 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:03:01,818 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:03:01,903 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:03:01,905 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:03:02,332 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:03:03,555 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:03:03,949 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:03:03,965 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:03:03,966 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:03:04,277 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:03:04,567 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:03:04,568 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:03:05,078 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:03:05,980 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:03:06,398 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:03:11,312 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:03:11,726 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:03:11,745 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:03:11,746 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:03:12,009 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:03:12,010 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:03:17,555 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:03:17,702 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:03:17,945 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:03:18,069 - JobSpy - INFO - Glassdoor finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:03:18,085 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:03:18,086 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:03:18,332 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:03:18,333 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:03:19,042 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:03:19,479 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:03:24,682 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:03:55,966 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:03:55,982 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:03:55,983 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:03:56,682 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:03:57,201 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:03:57,202 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:03:58,441 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:03:59,413 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:03:59,913 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:04:02,529 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:04:09,855 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-09-22 15:04:10,619 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:04:10,638 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:04:10,638 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:04:10,982 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:04:10,984 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:04:11,533 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:04:11,966 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:04:24,929 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:04:25,369 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:04:25,387 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:04:25,387 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:04:25,741 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:04:25,743 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:04:26,285 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:04:27,015 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:04:29,580 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:04:30,000 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:04:30,016 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:04:30,017 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:04:31,230 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:04:31,713 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:04:31,714 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:04:32,376 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:04:33,635 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:04:34,137 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:04:34,852 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:04:42,469 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-09-22 15:04:42,939 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:04:42,983 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:04:42,983 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:04:44,166 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:04:44,271 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:04:44,571 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:04:44,572 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:04:45,280 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:04:45,762 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:04:49,256 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:04:56,344 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-09-22 15:04:56,810 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:04:56,857 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:04:56,857 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:04:57,331 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:04:57,687 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:04:57,689 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:04:58,467 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:04:58,914 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:05:00,960 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:05:05,805 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-09-22 15:05:09,471 - JobSpy - INFO - LinkedIn search page: 4\n",
      "2024-09-22 15:05:09,866 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:05:09,901 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:05:09,901 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:05:10,139 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:05:10,141 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:05:11,962 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:05:12,775 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:05:17,311 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:05:28,355 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:05:28,375 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:05:28,376 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:05:28,634 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:05:28,636 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:05:28,838 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:05:29,343 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:05:29,749 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:05:29,753 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:05:29,755 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:05:30,018 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:05:30,020 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:05:30,275 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:05:30,674 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:05:31,062 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:05:31,066 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:05:31,067 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:05:31,364 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:05:31,619 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:05:31,620 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:05:32,518 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:05:33,326 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:05:33,716 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:05:38,421 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:06:09,713 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:06:09,732 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:06:09,733 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:06:10,024 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:06:10,422 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:06:10,423 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:06:10,640 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:06:11,965 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:06:12,372 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:06:16,594 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:06:16,981 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:06:17,004 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:06:17,005 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:06:17,283 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:06:17,284 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:06:17,888 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:06:18,262 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:06:21,994 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:06:22,464 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:06:22,479 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:06:22,480 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:06:22,925 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:06:22,927 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:06:24,302 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:06:24,657 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:06:29,476 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:06:40,428 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:06:40,442 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:06:40,442 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:06:40,712 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:06:40,714 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:06:40,955 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:06:41,455 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:06:41,840 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:06:41,846 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:06:41,847 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:06:42,112 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:06:42,114 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:06:43,019 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:06:43,408 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:06:59,052 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:06:59,740 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:06:59,755 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:06:59,756 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:07:00,185 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:07:00,443 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:07:00,444 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:07:02,176 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:07:03,169 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:07:03,565 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:07:06,199 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:07:11,497 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-09-22 15:07:11,910 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:07:11,939 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:07:11,940 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:07:12,342 - JobSpy - INFO - Indeed found no jobs on page: 1\n",
      "2024-09-22 15:07:12,343 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:07:12,863 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:07:13,706 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:07:18,609 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:07:24,510 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-09-22 15:07:25,278 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:07:25,293 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:07:25,294 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:07:25,579 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:07:25,905 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:07:25,906 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:07:27,878 - JobSpy - INFO - Glassdoor search page: 1\n",
      "2024-09-22 15:07:28,690 - JobSpy - INFO - Glassdoor search page: 2\n",
      "2024-09-22 15:07:29,088 - JobSpy - INFO - Glassdoor finished scraping\n",
      "2024-09-22 15:07:40,963 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:07:41,472 - JobSpy - INFO - Linkedin finished scraping\n",
      "/var/folders/rq/sblr0l3n54d6_71k5t73dqk40000gn/T/ipykernel_7540/1661203827.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
      "2024-09-22 15:07:41,488 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:07:41,489 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:07:41,878 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:07:42,195 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:07:42,195 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:07:46,972 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:07:54,097 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-09-22 15:07:57,745 - JobSpy - INFO - LinkedIn search page: 4\n",
      "2024-09-22 15:07:58,268 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:07:58,273 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:07:58,274 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:07:58,716 - JobSpy - INFO - Indeed search page: 2\n",
      "2024-09-22 15:07:59,086 - JobSpy - INFO - Indeed found no jobs on page: 2\n",
      "2024-09-22 15:07:59,087 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:08:29,603 - JobSpy - ERROR - LinkedIn: HTTPSConnectionPool(host='www.linkedin.com', port=443): Max retries exceeded with url: /jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=.net+relocate&location=UK&distance=50&pageNum=0&start=0&f_TPR=r259200 (Caused by ResponseError('too many 429 error responses'))\n",
      "2024-09-22 15:08:29,620 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-09-22 15:08:29,624 - JobSpy - INFO - Indeed search page: 1\n",
      "2024-09-22 15:08:29,625 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-09-22 15:08:30,343 - JobSpy - INFO - Indeed finished scraping\n",
      "2024-09-22 15:08:34,811 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-09-22 15:08:39,618 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-09-22 15:08:47,124 - JobSpy - INFO - LinkedIn search page: 4\n",
      "2024-09-22 15:08:47,829 - JobSpy - INFO - Linkedin finished scraping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 223 jobs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BEGIN: Combine all results into a single DataFrame\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "for location, results in Locations.items():\n",
    "        for suffix in job_sefixes:\n",
    "            try:\n",
    "                temp_df = scrape_jobs(\n",
    "                site_name=[\n",
    "                        \"Glassdoor\",\n",
    "                        \"indeed\",\n",
    "                        \"LinkedIn\",\n",
    "                        # \"zip_recruiter\"\n",
    "                    ],\n",
    "                    search_term=f\"{job_title} {suffix}\",\n",
    "                    location=location,\n",
    "                    results_wanted=results,\n",
    "                    country_indeed=location,\n",
    "                    hours_old=years_old,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                 continue\n",
    "            all_results = pd.concat([all_results, temp_df], ignore_index=True)\n",
    "\n",
    "print(f\"Found {len(all_results)} jobs\")\n",
    "# print(all_results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distintcs are: 18\n"
     ]
    }
   ],
   "source": [
    "distinct_jobs = all_results.drop_duplicates(subset=['title', 'company'])\n",
    "\n",
    "first_dict_words = [\"c#\", \" .net \", \"asp.net\", \"dotnet\", \"dot net\", \"csharp\", \"c sharp\", \"c-sharp\",]\n",
    "\n",
    "second_dict_words = [\"reloc\", \"visa\" , \"sponsor\", \"relocate\", \"relocation\"]\n",
    "\n",
    "def contains_both_word_sets(description, first_words, second_words):\n",
    "    if pd.isna(description):\n",
    "        return False\n",
    "    description_lower = description.lower()\n",
    "    return any(word in description_lower for word in first_words) and any(word in description_lower for word in second_words)\n",
    "\n",
    "distinct_jobs = distinct_jobs[distinct_jobs['description'].apply(lambda x: contains_both_word_sets(x, first_dict_words, second_dict_words))]\n",
    "\n",
    "distinct_jobs = distinct_jobs.sort_values(by='date_posted', ascending=False)\n",
    "print(f\"distintcs are: {len(distinct_jobs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_jobs.to_csv(f\"jobs-{date.today()}.csv\", quoting=csv.QUOTE_NONNUMERIC, escapechar=\"\\\\\", index=False) # to_excel\n",
    "# print(distinct_jobs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
